{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eldA-sl8YsLp"
      },
      "source": [
        "# Week 2: Principal Component Analysis\n",
        "\n",
        "**Student Name 1, Student Name 2** \n",
        "\n",
        "In this workshop, we will work through a set of problems on dimensionality reduction -- a cannonical form of unsupervised learning. Within the machine learning pipeline, dimensionality reduction is an important tool, which can used in EDA to understand patterns in the data, feature engineering to create a low-dimensional representation of the inputs, and/or in the final phase when you are presenting and visualizing your solution.\n",
        "\n",
        "As usual, the worksheets will be completed in teams of 2-3, using **pair programming**, and we have provided cues to switch roles between driver and navigator. When completing worksheets:\n",
        "\n",
        ">- You will have tasks tagged by (CORE) and (EXTRA). \n",
        ">- Your primary aim is to complete the (CORE) components during the WS session, afterwards you can try to complete the (EXTRA) tasks for your self-learning process. \n",
        ">- Look for the üèÅ as cue to switch roles between driver and navigator.\n",
        ">- In some Exercises, you will see some beneficial hints at the bottom of questions.\n",
        "\n",
        "Instructions for submitting your workshops can be found at the end of worksheet. As a reminder, you must submit a pdf of your notebook on Learn by 16:00 PM on the Friday of the week the workshop was given. \n",
        "\n",
        "As you work through the problems it will help to refer to your lecture notes (navigator). The exercises here are designed to reinforce the topics covered this week. Please discuss with the tutors if you get stuck, even early on! "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Outline\n",
        "\n",
        "1. [Problem Definition and Setup](#setup)\n",
        "\n",
        "2. [Principal Component Analysis](#pca)\n",
        "\n",
        "    a. [Examining the Basis Vectors and Scores](#basis)\n",
        "\n",
        "    b. [Selecting the Number of Components](#nocomponents)\n",
        "\n",
        "    c. [Other Digits](#other)\n",
        "\n",
        "3. [Kernel PCA](#kpca)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hm6XqPScK-FV"
      },
      "source": [
        "# Problem Definition and Setup <a id='setup'></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Packages\n",
        "\n",
        "First, lets load in some packages to get us started. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "executionInfo": {
          "elapsed": 3,
          "status": "ok",
          "timestamp": 1674743647585,
          "user": {
            "displayName": "Jacob Page",
            "userId": "04818256562649201928"
          },
          "user_tz": 0
        },
        "id": "usEZAe6SYpV8"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt  # plotting API (Matplotlib)\n",
        "import seaborn as sns  # statistical plotting styles/helpers (Seaborn)\n",
        "import numpy as np  # numerical arrays and linear algebra (NumPy)\n",
        "import pandas as pd  # tabular data structures (pandas)\n",
        "from sklearn.decomposition import PCA  # principal component analysis transformer\n",
        "from sklearn.preprocessing import StandardScaler  # z-score standardization transformer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSj3Z820mFwv"
      },
      "source": [
        "## Data\n",
        "\n",
        "Our dataset will be the famous [MNIST](http://yann.lecun.com/exdb/mnist/) dataset of handwritten digits, which we will download from sklearn. The dataset consists of a set of greyscale images of the numbers 0-9 and corresponding labels. Usually the goal is to train a classifier (i.e. given an image, what digit does it correspond to?). Here we will throw away the labels and focus on the images themselves. Specifically, we will use dimensionality reduction to explore the images and underlying patterns and find a low-dimensional representation.\n",
        "\n",
        "First, load the data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_openml  # utility to download datasets from OpenML\n",
        "\n",
        "mnist = fetch_openml('mnist_784', parser='auto')  # load MNIST (784 features/pixels per image)\n",
        "X = mnist.data  # feature matrix: rows are images, columns are pixel intensities\n",
        "y = mnist.target  # labels/targets: digit class for each image (often stored as strings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qeHcm_OBGhtx"
      },
      "source": [
        "### üö© Exercise 1 (CORE)\n",
        "\n",
        "What is stored in `X` and `y` in the command above? What is the shape/datatype etc if an array?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Code for your answer here!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "_Type your answer here!_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5q1xG24emmdu"
      },
      "source": [
        "Now, let's create a dictionary, with the digit classes (0-9) as keys, where the correponding values are the set of all images corresponding to that particular label. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 234,
          "status": "ok",
          "timestamp": 1674743872754,
          "user": {
            "displayName": "Jacob Page",
            "userId": "04818256562649201928"
          },
          "user_tz": 0
        },
        "id": "nCExrjAlmQOm"
      },
      "outputs": [],
      "source": [
        "digits_dict = {}  # initialise dict: label (0-9) -> list of image vectors\n",
        "X_ = X.values  # convert the pandas DataFrame `X` into a NumPy array for fast row indexing\n",
        "count = 0  # row counter to keep X_ aligned with the current label in `y`\n",
        "\n",
        "for label in y:  # iterate over each label in the same order as the rows of `X`\n",
        "  if label in digits_dict:  # if we've seen this label before, append to its list\n",
        "    digits_dict[label] += [X_[count]]  # add the current image (row) to the label's list\n",
        "  else:  # if this is the first time we see this label, create the list\n",
        "    digits_dict[label] = [X_[count]]  # start a new list containing the current image (row)\n",
        "  count += 1  # increment row index so the next label matches the next image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next let's visualize some of the images. We will start by picking a label and plotting a few images from within the dictionary. Note that each image contains a total of 784 pixels (28 by 28) and we will need to `reshape` the image to plot with `imshow(...,cmap='gray_r')`. Try also changing the label to view different digits."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mylabel = '1'  # choose which digit label to visualise (as stored in `y`, often strings like '1')\n",
        "n_images_per_label = 5  # how many examples of this digit to plot\n",
        "\n",
        "fig = plt.figure(figsize=(4 * n_images_per_label, 4))  # create a figure sized to fit `n_images_per_label` images\n",
        "for j in range(n_images_per_label):  # loop over the first `n_images_per_label` images for this label\n",
        "    ax_number = 1 + j  # subplot index (Matplotlib subplots are 1-indexed here)\n",
        "    ax = fig.add_subplot(1, n_images_per_label, ax_number)  # add a subplot in a 1 x n_images_per_label grid\n",
        "    ax.imshow(digits_dict[mylabel][j].reshape((28, 28)), cmap='gray_r')  # reshape vector -> 28x28 and plot in grayscale\n",
        "    ax.set_xticks([])  # hide x-axis tick marks for cleaner image display\n",
        "    ax.set_yticks([])  # hide y-axis tick marks for cleaner image display\n",
        "fig.tight_layout()  # automatically adjust spacing so subplots don't overlap"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z95pdmrynwyX"
      },
      "source": [
        "### üö© Exercise 2 (EXTRA)\n",
        "\n",
        "Edit the code above to plot a few images for multiple labels.\n",
        "\n",
        "<br>\n",
        "<details><summary><b><u>Hint</b></u></summary>\n",
        "\n",
        "Create a vector of labels and add additional for loop in the code above.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 873
        },
        "executionInfo": {
          "elapsed": 616,
          "status": "ok",
          "timestamp": 1674743876957,
          "user": {
            "displayName": "Jacob Page",
            "userId": "04818256562649201928"
          },
          "user_tz": 0
        },
        "id": "98lyOLGKmjam",
        "outputId": "76cd9822-4e86-44d7-8bfe-7dfed42686fe"
      },
      "outputs": [],
      "source": [
        "# Code for your answer here!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9R_1TGs8rInz"
      },
      "source": [
        "### üö© Exercise 3 (CORE)\n",
        "\n",
        "Now focus on the 3s only and create a data matrix called `X_threes`. Define also `N` (# datapoints) and `D` (# features).\n",
        "\n",
        "What are the features in this problem? How many features and data points are there? "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 225,
          "status": "ok",
          "timestamp": 1674743879981,
          "user": {
            "displayName": "Jacob Page",
            "userId": "04818256562649201928"
          },
          "user_tz": 0
        },
        "id": "HhzuQdIuptAh",
        "outputId": "274c220d-7d32-4942-a82c-49909efceef0"
      },
      "outputs": [],
      "source": [
        "# Code for your answer here!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "_Type your answer here!_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IAtBj2cRs6RZ"
      },
      "source": [
        "### üö© Exercise 4 (CORE)\n",
        "\n",
        "Now compute and plot the mean image of three."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "executionInfo": {
          "elapsed": 274,
          "status": "ok",
          "timestamp": 1674743895536,
          "user": {
            "displayName": "Jacob Page",
            "userId": "04818256562649201928"
          },
          "user_tz": 0
        },
        "id": "z3sD-Qyjs5vz",
        "outputId": "a32a5957-f43a-4e9c-8d34-7750f2e7e85b"
      },
      "outputs": [],
      "source": [
        "# Code for your answer here!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run the following code to first create a new data matrix that centers the data by subtracting the mean image, and then visualise some of the images and compare to the original data. Note: you will need to replace `X_three_mean` with the name you gave the mean image in the computation above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 587
        },
        "executionInfo": {
          "elapsed": 849,
          "status": "ok",
          "timestamp": 1674743904757,
          "user": {
            "displayName": "Jacob Page",
            "userId": "04818256562649201928"
          },
          "user_tz": 0
        },
        "id": "Y3YJUQDIr_-G",
        "outputId": "d3cf35a0-db7d-4c25-b798-dfd013c16d49"
      },
      "outputs": [],
      "source": [
        "X_three_centred = X_threes - X_three_mean  # centre each image by subtracting the mean image (pixel-wise)\n",
        "\n",
        "n_images = 5  # number of example images to show\n",
        "\n",
        "fig = plt.figure(figsize=(4 * n_images, 4 * 2))  # create a figure with 2 rows (centred vs original)\n",
        "for j in range(n_images):  # loop over a few images to visualise\n",
        "  ax = fig.add_subplot(2, n_images, j + 1)  # top row: centred images\n",
        "  ax.imshow(X_three_centred[j, :].reshape((28, 28)), cmap='gray_r')  # reshape and plot centred image j\n",
        "  ax.set_xticks([])  # hide x ticks\n",
        "  ax.set_yticks([])  # hide y ticks\n",
        "\n",
        "  ax = fig.add_subplot(2, n_images, j + 1 + n_images)  # bottom row: original (uncentred) images\n",
        "  ax.imshow(X_threes[j, :].reshape((28, 28)), cmap='gray_r')  # reshape and plot original image j\n",
        "  ax.set_xticks([])  # hide x ticks\n",
        "  ax.set_yticks([])  # hide y ticks\n",
        "fig.tight_layout()  # adjust subplot spacing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üö© Exercise 5 (CORE)\n",
        "\n",
        "Comment on whether or not the images need to be standardized before using PCA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "_Type your answer here!_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "üèÅ **Now, is a good point to switch driver and navigator**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# PCA <a id='pca'></a>\n",
        "\n",
        "Now, we will perform PCA to summarize the main patterns in the images. We will use the [`PCA()`](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html) transformer from the `sklearn.decomposition` package:\n",
        "\n",
        "- As we saw last week, we start by creating our transformer object, specifying any parameters as desired. For example, we can specify the number of components with the option `n_components`. If omitted, all components are kept.\n",
        "\n",
        "- Note that by default the `PCA()` transform centers the variables to have zero mean (but does not scale them). \n",
        "\n",
        "- After calling `.fit()`, our fitted object has a number of attributes, including:\n",
        "    - the mean accessible through the attribute `mean_`.\n",
        "    - the basis vectors (principal components) accesible through the `components_` attribute.\n",
        "\n",
        "- There are also a number of methods for the fitted object, including `.transform()` to obtain the low-dimensional representation (or also `fit_transform` combining both together). \n",
        "\n",
        " First, let's create the PCA transformer object and call `.fit()`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pca_threes = PCA(n_components=200)  # create PCA object keeping the first 200 principal components\n",
        "pca_threes.fit(X_threes)  # fit PCA to the digit-3 data (computes mean and components)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Examining the Basis Vectors and Scores <a id='basis'></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üö© Exercise 6 (EXTRA)\n",
        " \n",
        "Plot the mean image by accessing the `mean_` attribute and check that it is the same as above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Code for your answer here!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üö© Exercise 7 (CORE)\n",
        "\n",
        "Plot the the first four basis vectors as images by accessing the `components_` attribute. What patterns do they seem describe? "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Code for your answer here!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "_Type your answer here!_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üö© Exercise 8 (CORE)\n",
        "\n",
        "a) Use the `transform()` method to compute the PCA scores and save them in an object called `scores`. Then, plot the data points in the low-dimensional space spanned by the first two principal components. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Code for your answer here!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To better interpret the latent dimensions, let's look at some projected points along each dimension and the corresponding images. Specifically, run the following code to:\n",
        "\n",
        "- first compute the $5, 25, 50, 75, 95\\%$ quantiles of the scores for the first two dimensions\n",
        "- then find the data point whose projection is closest to each combination of quantiles."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "s1q = np.quantile(scores[:, 0], [.05, .25, .5, .75, .95])  # compute 5/25/50/75/95% quantiles for PC1 scores\n",
        "s2q = np.quantile(scores[:, 1], [.05, .25, .5, .75, .95])  # compute 5/25/50/75/95% quantiles for PC2 scores\n",
        "\n",
        "idx = np.zeros([len(s1q), len(s2q)])  # allocate array to store indices of closest points to each (PC1, PC2) quantile pair\n",
        "\n",
        "for i in range(len(s1q)):  # loop over PC1 quantiles\n",
        "    for j in range(len(s2q)):  # loop over PC2 quantiles\n",
        "        aux = ((scores[:, 0] - s1q[i]) ** 2 + (scores[:, 1] - s2q[j]) ** 2).reshape(N, 1)  # squared distance to target quantile pair\n",
        "        idx[i, j] = np.where(aux == min(aux))[0][0]  # index of the point with minimum distance (closest projection)\n",
        "\n",
        "idx = idx.astype(int)  # cast indices to integers for array indexing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "b) Now, add these points in red to your plot above in."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Code for your answer here!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "c) Run the following code to plot the images corresponding to this grid of points. Describe the general pattern of the first (left to right) and second (down to up) principal component."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(len(s1q), len(s2q), figsize=(6, 6))  # create a grid of subplots (PC1 quantiles x PC2 quantiles)\n",
        "for i in range(len(s1q)):  # iterate over PC1 quantile levels (columns)\n",
        "    for j in range(len(s2q)):  # iterate over PC2 quantile levels (rows)\n",
        "        ax[len(s2q) - 1 - j, i].imshow(X_threes[idx[i, j], :].reshape((28, 28)), cmap='gray_r')  # plot the closest image at that quantile pair\n",
        "plt.setp(ax, xticks=[], yticks=[])  # remove axis ticks for all subplots\n",
        "fig.tight_layout()  # reduce overlap and improve spacing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "_Type your answer here!_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can also try to create some artificial images, by fixing different values of the weights. This can also help to interpret the latent dimensions. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "weight1 = np.quantile(scores[:, 0], [.05, .25, .5, .75, .95])  # choose representative PC1 score values via quantiles\n",
        "weight2 = 0  # fix PC2 weight to 0 so we vary only along the first component\n",
        "\n",
        "images_pc1 = np.zeros([len(weight1), D])  # allocate array for synthetic images (one per chosen PC1 weight)\n",
        "\n",
        "count = 0  # counter to place each generated image into `images_pc1`\n",
        "for w in weight1:  # iterate over selected PC1 weights\n",
        "    images_pc1[count, :] = (pca_threes.mean_ + pca_threes.components_[0, :] * w + pca_threes.components_[1, :] * weight2)  # reconstruct from mean + weighted PCs\n",
        "    count += 1  # move to next row in `images_pc1`\n",
        "    \n",
        "\n",
        "fig, ax = plt.subplots(1, len(weight1), figsize=(10, 6))  # create a row of subplots to display generated images\n",
        "for i in range(len(weight1)):  # loop over the generated images\n",
        "    ax[i].imshow(images_pc1[i, :].reshape((28, 28)), cmap='gray_r')  # reshape and show the i-th synthetic image\n",
        "plt.setp(ax, xticks=[], yticks=[])  # remove ticks for cleaner presentation\n",
        "fig.tight_layout()  # adjust layout to prevent overlap"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üö© Exercise 9 (CORE)\n",
        "\n",
        "Repeat this to describe the third principal component. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Code for your answer here!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "_Type your answer here!_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üö© Exercise 10 (EXTRA)\n",
        "\n",
        "In lecture, we saw that we can also compute the basis vectors from an SVD decomposition of the data matrix. Use the `svd` function in `scipy.linalg` to compute the first three basis vectors and verify that they are the same (up to a change in sign -- note that the signs may be flipped because each principal component specifies a direction in the $D$-dimensional space and flipping the sign has no effect as the direction does not change). \n",
        "\n",
        "Does `PCA()` perform principal component analysis using an eigendecomposition of the empirical covariance matrix or using a SVD decomposition of the data matrix?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Code for your answer here!\n",
        "from scipy.linalg import svd  # import singular value decomposition (SVD) for computing PCs via matrix factorisation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "_Type your answer here!_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "üèÅ **Now, is a good point to switch driver and navigator**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Selecting the Number of Components <a id='nocomponents'></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üö© Exercise 11 (CORE)\n",
        "\n",
        "Next, let's investigate how many components are needed by considering how much variance is explained by each component.\n",
        "\n",
        "Note that the `pca_threes` object has an attribute `explained_variance_` (variance of each component) and `explained_variance_ratio_` (proportion of variance explained by each component). \n",
        "\n",
        "Plot both the proportion of variance explained and the cummulative proportion of variance explained. Provide a suggestion of how many components to use. How much variance is explained by the suggest number of components? Comment on why we may be able to use this number of components in relation to the total number of features.\n",
        "\n",
        "<br>\n",
        "<details><summary><b><u>Hint</b></u></summary>\n",
        "\n",
        "You can use `cumsum()` to compute the cummulative sum of the elements in a vector.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Code for your answer here!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "_Type your answer here!_ "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üö© Exercise 12 (CORE)\n",
        "\n",
        "For your selected number of components, compute the reconstruted images. Plot the reconstruction for a few images and compare with the original images. Comment on the results.  \n",
        "\n",
        "<br>\n",
        "<details><summary><b><u>Hint</b></u></summary>\n",
        "\n",
        "You can use `inverse_transform()` to decode the scores.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Code for your answer here!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "_Type your answer here!_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "üèÅ **Now, is a good point to switch driver and navigator**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Other Digits <a id='other'></a>\n",
        "\n",
        "Now, let's consider another digit. \n",
        "\n",
        "### üö© Exercise 13 (CORE)\n",
        "\n",
        "Perform PCA for another choice of digit. What do the first two components describe? Do some digits have better approximations than others? Comment on why this may be."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cpde for your answer here!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "_Type your answer here!_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4-MKAQNiloz"
      },
      "source": [
        "### Exercise 14 (EXTRA)\n",
        "\n",
        "Finally, consider now two digits of your choice (edit the code below if you wish to pick different digits).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract data  \n",
        "X_twodigits = np.concatenate((digits_dict['3'], digits_dict['8']))  # stack all '3' and all '8' images into one dataset\n",
        "N, D = X_twodigits.shape  # store dataset size: N images (rows), D pixels/features (columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run the following code to compute and plot the mean and some of the principle components for this dataset. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LfvsQJkHiMnq"
      },
      "outputs": [],
      "source": [
        "# Fit PCA\n",
        "pca_digits = PCA(n_components=50)  # create PCA transformer keeping the first 50 components\n",
        "pca_digits.fit(X_twodigits)  # fit PCA on the two-digit dataset (learns mean and components)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot the mean image\n",
        "fig = plt.figure(figsize=(5, 5))  # create a square figure for the mean digit image\n",
        "ax = fig.add_subplot(111)  # add a single subplot occupying the whole figure\n",
        "ax.imshow(pca_digits.mean_.reshape(28, 28), cmap='gray_r')  # reshape mean vector to 28x28 and display in grayscale\n",
        "ax.set_xticks([])  # remove x-axis ticks\n",
        "ax.set_yticks([])  # remove y-axis ticks\n",
        "fig.tight_layout()  # tidy spacing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot basis vectors\n",
        "n_plot = 5  # number of principal components to visualise\n",
        "fig, ax = plt.subplots(1, 5, figsize=(10, 4))  # create a row of 5 subplots for the first 5 PCs\n",
        "for n in range(n_plot):  # loop over the first `n_plot` principal components\n",
        "  ax[n].imshow(pca_digits.components_[n, :].reshape((28, 28)), cmap='gray_r')  # reshape PC vector to 28x28 and display\n",
        "plt.setp(ax, xticks=[], yticks=[])  # remove ticks on all subplots\n",
        "fig.tight_layout()  # adjust spacing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot the projection of the data in the latent space and color the data by the labels. What do you observe?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Code for your answer here!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "_Type your answer here!_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Try also to generate artificial images and decsribe how images change along the PCs. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Code for your answer here!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "_Type your answer here!_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Kernel PCA <a id='kpca'></a>\n",
        "\n",
        "Now, let's try using kernel PCA, which is available through sklearn's [`KernelPCA`](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.KernelPCA.html) transformer. As usual we start by creating our object and specifying parameters (see documentation to learn more about the optional parameters). Then, we use the methods `.fit()` and `.transform()` to fit the object and obtain the lower-dimensional representation.\n",
        "\n",
        "In the code below, we use the radial basis function kernel, with the inverse bandwith parameter `gamma` set to 0.05. Setting, the option `fit_inverse_transform=True` will allow us to reconstruct the images later (and `alpha` is regularization used when inversing the transforming).\n",
        "\n",
        "_Note:_ we first subsampled the data, as kernel PCA can be slow on large datasets.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.decomposition import KernelPCA  # kernel PCA transformer for nonlinear dimensionality reduction\n",
        "from sklearn.model_selection import train_test_split  # utility to split arrays into train/test subsets\n",
        "from sklearn.preprocessing import MinMaxScaler  # scaler to map features into a fixed range (default [0, 1])\n",
        "\n",
        "# Prepare data\n",
        "y_twodigits = y_twodigits.astype(int)  # ensure labels are integer-coded (useful for comparisons/plotting)\n",
        "X_twodigits = MinMaxScaler().fit_transform(X_twodigits)  # scale pixel values to [0, 1] before applying kernels\n",
        "\n",
        "# Subsample the images (for speed)\n",
        "X_twodigits_subsampled, X_twodigits_test, y_twodigits_subsampled, y_twodigits_test = train_test_split(  # split into a smaller training subset and a held-out test set\n",
        "    X_twodigits,  # full feature matrix for the two digits\n",
        "    y_twodigits,  # corresponding digit labels\n",
        "    stratify=y_twodigits,  # preserve class proportions in both splits\n",
        "    random_state=0,  # seed for reproducibility\n",
        "    train_size=500,  # number of samples to keep for fitting (subsample)\n",
        "    test_size=100  # number of samples to reserve for evaluation/denoising\n",
        ")  # end train/test split call\n",
        "\n",
        "# Define our KPCA and PCA transformers\n",
        "n_components = 10  # number of latent dimensions/components to keep\n",
        "kpca = KernelPCA(  # construct the kernel PCA model\n",
        "    n_components=n_components,  # dimensionality of the KPCA embedding\n",
        "    kernel=\"rbf\",  # radial basis function (Gaussian) kernel\n",
        "    gamma=0.05,  # inverse bandwidth for the RBF kernel (controls nonlinearity)\n",
        "    fit_inverse_transform=True,  # enable approximate inverse mapping for reconstructions\n",
        "    random_state=0,  # seed (used in some solver paths)\n",
        "    alpha=0.01  # regularisation for the inverse transform\n",
        ")  # end KPCA model definition\n",
        "\n",
        "pca = PCA(n_components=n_components)  # define standard (linear) PCA baseline with the same number of components\n",
        "\n",
        "# Fit and transform the data\n",
        "scores_kpca = kpca.fit_transform(X_twodigits_subsampled)  # fit KPCA on the subsample and return low-D scores\n",
        "scores_pca = pca.fit_transform(X_twodigits_subsampled)  # fit PCA on the subsample and return low-D scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, let's plot the images in the space of the first two components for both kernel PCA and standard PCA."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot the images in the space of the first two components, colored by digit\n",
        "i, j = 0, 1  # component indices to plot (0-based: first vs second component)\n",
        "yu = [3, 8]  # the digit classes to plot\n",
        "fig, ax = plt.subplots(1, 2, figsize=(10, 5))  # create a 1x2 panel: KPCA scatter (left) vs PCA scatter (right)\n",
        "for dig in yu:  # loop over the digit classes so each class gets its own colour/label\n",
        "    ax[0].scatter(  # scatter plot for kernel PCA scores\n",
        "        scores_kpca[y_twodigits_subsampled == dig, i],  # x-coordinates: component i scores for this digit\n",
        "        scores_kpca[y_twodigits_subsampled == dig, j],  # y-coordinates: component j scores for this digit\n",
        "        c=colors[dig],  # point colour for this digit class\n",
        "        label=dig  # legend label for this digit class\n",
        "    )  # end KPCA scatter\n",
        "    ax[1].scatter(  # scatter plot for standard PCA scores\n",
        "        scores_pca[y_twodigits_subsampled == dig, i],  # x-coordinates: component i scores for this digit\n",
        "        scores_pca[y_twodigits_subsampled == dig, j],  # y-coordinates: component j scores for this digit\n",
        "        c=colors[dig],  # point colour for this digit class\n",
        "        label=dig  # legend label for this digit class\n",
        "    )  # end PCA scatter\n",
        "ax[0].legend()  # show legend for the kernel PCA panel\n",
        "ax[0].set_xlabel('PCA%d' % (i + 1))  # label x-axis with component number (1-based for display)\n",
        "ax[0].set_ylabel('PCA%d' % (j + 1))  # label y-axis with component number (1-based for display)\n",
        "ax[0].set_title('Kernel PCA')  # title for the kernel PCA subplot\n",
        "ax[1].legend()  # show legend for the standard PCA panel\n",
        "ax[1].set_xlabel('PCA%d' % (i + 1))  # label x-axis for the PCA subplot\n",
        "ax[1].set_ylabel('PCA%d' % (j + 1))  # label y-axis for the PCA subplot\n",
        "ax[1].set_title('Standard PCA')  # title for the standard PCA subplot\n",
        "plt.show()  # render the figure"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Image Denoising\n",
        "Let's add some noise to our test images that weren't used in the fitting. We will then encode the noisy images into the latent space and then reconstruct our images, to see how well both methods are able to denoise the images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Add noise to the test images\n",
        "np.random.seed(0)  # set RNG seed so the added noise is reproducible\n",
        "noise = np.random.normal(0, 0.1, X_twodigits_test.shape)  # sample Gaussian noise with mean 0 and std 0.1\n",
        "X_twodigits_test_noisy = X_twodigits_test + noise  # create noisy test images by adding noise pixel-wise\n",
        "\n",
        "# Plot some noisy test images\n",
        "n_images = 5  # number of test images to visualise\n",
        "fig, ax = plt.subplots(2, n_images, figsize=(2 * n_images, 4))  # create a 2-row grid: original (top) vs noisy (bottom)\n",
        "for j in range(n_images):  # loop over a few example images\n",
        "    ax[0, j].imshow(X_twodigits_test[j].reshape((28, 28)), cmap='gray_r')  # plot original image j\n",
        "    ax[1, j].imshow(X_twodigits_test_noisy[j].reshape((28, 28)), cmap='gray_r')  # plot noisy version of image j\n",
        "plt.setp(ax, xticks=[], yticks=[])  # remove ticks on all axes for cleaner display\n",
        "# Add titles\n",
        "ax[0, 2].set_title('Original Images')  # title for the original row (placed on the middle subplot)\n",
        "ax[1, 2].set_title('Noisy Images')  # title for the noisy row (placed on the middle subplot)\n",
        "fig.tight_layout()  # adjust spacing to avoid overlaps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Now transform the noisy test images using both PCA and KernelPCA\n",
        "scores_kpca_test = kpca.transform(X_twodigits_test_noisy)  # encode noisy test images into KPCA latent space\n",
        "scores_pca_test = pca.transform(X_twodigits_test_noisy)  # encode noisy test images into PCA latent space\n",
        "\n",
        "# And reconstruct the noisy test images using both PCA and KernelPCA\n",
        "X_reconstructed_kpca = kpca.inverse_transform(  # decode KPCA scores back to pixel space (approximate inverse)\n",
        "    scores_kpca_test  # the KPCA scores for noisy test images\n",
        ")  # end KPCA reconstruction\n",
        "X_reconstructed_pca = pca.inverse_transform(  # decode PCA scores back to pixel space\n",
        "    scores_pca_test  # the PCA scores for noisy test images\n",
        ")  # end PCA reconstruction\n",
        "\n",
        "# Plot some reconstructed images\n",
        "n_images = 5  # number of images to show in each row\n",
        "fig, ax = plt.subplots(4, n_images, figsize=(2 * n_images, 8))  # create a 4-row grid: original, noisy, KPCA recon, PCA recon\n",
        "for j in range(n_images):  # loop over the selected test images\n",
        "    ax[0, j].imshow(X_twodigits_test[j].reshape((28, 28)), cmap='gray_r')  # plot original image j\n",
        "    ax[1, j].imshow(X_twodigits_test_noisy[j].reshape((28, 28)), cmap='gray_r')  # plot noisy image j\n",
        "    ax[2, j].imshow(X_reconstructed_kpca[j].reshape((28, 28)), cmap='gray_r')  # plot KPCA reconstruction of image j\n",
        "    ax[3, j].imshow(X_reconstructed_pca[j].reshape((28, 28)), cmap='gray_r')  # plot PCA reconstruction of image j\n",
        "plt.setp(ax, xticks=[], yticks=[])  # remove ticks on all subplots\n",
        "# Add titles\n",
        "ax[0, 2].set_title('Original Images')  # title for the original row (placed in the middle column)\n",
        "ax[1, 2].set_title('Noisy Images')  # title for the noisy row\n",
        "ax[2, 2].set_title('Reconstructed Images (Kernel PCA)')  # title for the KPCA reconstruction row\n",
        "ax[3, 2].set_title('Reconstructed Images (Standard PCA)')  # title for the PCA reconstruction row\n",
        "fig.tight_layout()  # adjust subplot spacing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise 15 (EXTRA)\n",
        "\n",
        "a) Try changing the `gamma`. What happens when you increase, e.g. `gamma=0.1`? Or decrease `gamma=0.01`? \n",
        "\n",
        "b) Try changing the number of components. How does this affect the reconstructed images for both PCA and kernel PCA?\n",
        "\n",
        "c) Which method would you prefer for this dataset?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "_Type your answer here!_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Competing the Worksheet\n",
        "\n",
        "At this point you have hopefully been able to complete all the CORE exercises and attempted the EXTRA ones. Now \n",
        "is a good time to check the reproducibility of this document by restarting the notebook's\n",
        "kernel and rerunning all cells in order.\n",
        "\n",
        "Before generating the PDF, please **change 'Student 1' and 'Student 2' at the top of the notebook to include your name(s)**. \n",
        "\n",
        "Once that is done and you are happy with everything, you can then run the following cell \n",
        "to generate your PDF."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!jupyter nbconvert --to pdf mlp_week02_key.ipynb"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.0"
    },
    "title": "MLP Workshop 2"
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
